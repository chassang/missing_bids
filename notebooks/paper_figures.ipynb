{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from missing_bids import auction_data, analytics, environments\n",
    "hist_plot = auction_data.hist_plot\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "sns.set_style('white')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data located at \n",
      "\t/home/sylvain/Dropbox/Econ/papiers/gameTheory/missing_bids/data/data_for_missing_bids_figures\n"
     ]
    }
   ],
   "source": [
    "# getting data directory\n",
    "\n",
    "path_data = '/home/sylvain/Dropbox/Econ/papiers/gameTheory/missing_bids/data/data_for_missing_bids_figures'\n",
    "#None #path/to/data (if you know it, otherwise, we'll find it below)\n",
    "\n",
    "if path_data is None:\n",
    "    name = 'data_for_missing_bids_figures'\n",
    "    for root, dirs, _ in os.walk('/'):\n",
    "        if name in dirs:\n",
    "            path_data = os.path.join(root, name)\n",
    "            break\n",
    "        \n",
    "print('data located at \\n\\t{}'.format(path_data))\n",
    "path_figures = os.path.join(path_data, 'figures')\n",
    "\n",
    "if not os.path.exists(path_figures):\n",
    "    os.makedirs(path_figures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set global optimization parameters\n",
    "\n",
    "num_points = 3000\n",
    "number_iterations = 5\n",
    "confidence_level = .95\n",
    "list_ks = [0.5, 1, 1.5, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_minimization_solution(data, deviations, max_markup=.5):\n",
    "    demands = [data.get_counterfactual_demand(rho) for rho in deviations]\n",
    "    solutions = []\n",
    "    filter_ties = auction_data.FilterTies(tolerance=.0001)\n",
    "    filtered_data = filter_ties(data)\n",
    "    share_ties = filter_ties.get_ties(data).mean()\n",
    "\n",
    "    for k in list_ks:\n",
    "        constraints = [environments.MarkupConstraint(max_markup=max_markup, min_markup=.02), \n",
    "                   environments.InformationConstraint(k=k, sample_demands=demands)]\n",
    "\n",
    "        min_collusion_solver = analytics.MinCollusionIterativeSolver(\n",
    "            data=filtered_data, \n",
    "            deviations=deviations, \n",
    "            metric=analytics.IsNonCompetitive, \n",
    "            plausibility_constraints=constraints, \n",
    "            num_points=num_points, \n",
    "            seed=0, \n",
    "            project=False, \n",
    "            filter_ties=None,\n",
    "            number_iterations=number_iterations,\n",
    "            confidence_level=confidence_level,\n",
    "            moment_matrix=auction_data.moment_matrix(deviations, 'slope'),\n",
    "            moment_weights=np.array([0, 0, 1])\n",
    "        )\n",
    "\n",
    "        share_collusive = min_collusion_solver.result.solution    \n",
    "        solutions.append(1 - share_collusive)\n",
    "        del min_collusion_solver\n",
    "    del filtered_data\n",
    "    return np.array(solutions), share_ties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_plot(title, list_solutions, labels, mark=['k.:', 'k.-']):\n",
    "    plt.title(title)\n",
    "    for i, (solutions, label) in enumerate(zip(list_solutions, labels)):\n",
    "        plt.plot(list_ks, solutions, mark[i], label=label)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.axis([list_ks[0], list_ks[-1], 0, 1.05])\n",
    "    plt.xlabel('k')\n",
    "    plt.ylabel('share of competitive histories')\n",
    "    plt.savefig(os.path.join(path_figures, '{}.pdf'.format(title)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2633498306850742, 0.17712946079708258, 0.17712946079708258]\n",
      "0.5983225146928144\n",
      "[0.15198956294846705, 0.1004566210045662, 0.1004566210045662]\n"
     ]
    }
   ],
   "source": [
    "national_data = auction_data.AuctionData('../tests/reference_data/sample_with_firm_rank.csv')\n",
    "filter_ties = auction_data.FilterTies(tolerance=.0001)\n",
    "filtered_data = filter_ties(national_data)\n",
    "\n",
    "comp_histories_firms_2 = []\n",
    "\n",
    "#firms = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
    "deviations = [-.025, .0, .001]\n",
    "count = 1\n",
    "\n",
    "while count < 11:\n",
    "    filtered_data_firm = auction_data.AuctionData.from_clean_bids(\n",
    "    filtered_data.df_bids.loc[filtered_data.data.rank2 == count])\n",
    "    demand_firm = [filtered_data_firm.get_counterfactual_demand(rho) for rho in deviations]\n",
    "    print(demand_firm)\n",
    "    constraints = [environments.MarkupConstraint(max_markup=.5, min_markup=.02), \n",
    "    environments.InformationConstraint(k=1, sample_demands=demand_firm)]\n",
    "\n",
    "    min_collusion_solver = analytics.MinCollusionIterativeSolver(\n",
    "        data=filtered_data_firm, \n",
    "        deviations=deviations, \n",
    "        metric=analytics.IsNonCompetitive, \n",
    "        plausibility_constraints=constraints, \n",
    "        num_points=30000.0, \n",
    "        seed=0, \n",
    "        project=False, \n",
    "        filter_ties=None,\n",
    "        number_iterations=500,\n",
    "        confidence_level=.95,\n",
    "        moment_matrix=auction_data.moment_matrix(deviations, 'slope'),\n",
    "        moment_weights=np.array([0, 0, 1])\n",
    "    )\n",
    "\n",
    "    share = min_collusion_solver.result.solution\n",
    "    print(1 - share) \n",
    "    comp_histories_firms_2.append(1 - share)\n",
    "    count = count + 1\n",
    "    \n",
    "print(comp_histories_firms_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5983225785780911, 0.6802485938054595, 0.5983227188764317, 0.999999999996455, 0.6802486191487804, 0.12868268014296702, 0.1540303084010337, 0.1484759388140957, 0.6802488600281172, 0.15403031065044115, 0.5983224688964097, 0.6802491370470429, 0.14847594652930796, 0.1484759388998611, 0.9457864553052578, 0.1540303097504846, 0.6802487829774598, 0.14847594204754122, 0.1484759389661695, 1.0000000000062657, 0.16394525190076736, 1.000000000007576, 0.16394525271129934, 1.000000000000639, 0.1639452517060359, 0.9627616318719026, 0.16394526207861293, 0.5983224878333374, 0.16394525409827598, 0.598322458065558]\n"
     ]
    }
   ],
   "source": [
    "print(comp_histories_firms_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
