{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from missing_bids import auction_data, analytics, environments\n",
    "hist_plot = auction_data.hist_plot\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "sns.set_style('white')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsuchiura_data = auction_data.AuctionData('../tests/reference_data/tsuchiura_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsuchiura_before_min_price = auction_data.AuctionData(\n",
    "    tsuchiura_data.df_bids.loc[tsuchiura_data.data.minprice.isnull()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.3686968225457008e-15, 0.9088236452805376, 0.7075331551103049]\n"
     ]
    },
    {
     "ename": "QhullError",
     "evalue": "QH6271 qhull precision error (qh_check_dupridge): wide merge (13495836560 times wider) due to duplicate ridge with nearly coincident points (1.7e-11) between f649 and f646, merge dist 0.00035, while processing p1000\n- Ignore error with option 'Q12'\n- To be fixed in a later version of Qhull\n- Vertex distance 1.7e-11 is greater than 100 times maximum distance 2.6e-14\n  Please report to bradb@shore.net with steps to reproduce and all output\nERRONEOUS FACET:\n- f649\n    - flags: top new dupridge mergeridge2 flipped\n    - normal:    0.7071  -0.7071 2.079e-07 0.0005327\n    - offset: -0.0005328684\n    - vertices: p1000(v67) p821(v56) p1111(v55) p1179(v9)\n    - neighboring facets: f470 f646 f647 f641\n    - ridges:\n     - r314 tested\n           vertices: p821(v56) p1111(v55) p1179(v9)\n           between f649 and f470\n     - r412\n           vertices: p1000(v67) p1111(v55) p1179(v9)\n           between f646 and f649\n     - r413\n           vertices: p1000(v67) p821(v56) p1179(v9)\n           between f649 and f647\n     - r414\n           vertices: p1000(v67) p821(v56) p1111(v55)\n           between f641 and f649\nERRONEOUS OTHER FACET:\n- f646\n    - flags: top new seen mergehorizon dupridge mergeridge1 flipped\n    - normal:        -0        0       -0       -1\n    - offset:          1\n    - vertices: p1000(v67) p1111(v55) p681(v11) p1179(v9)\n    - neighboring facets: f47 f649\n    - ridges:\n     - r282 tested\n           vertices: p1111(v55) p681(v11) p1179(v9)\n           between f646 and f47\n     - r410\n           vertices: p1000(v67) p681(v11) p1179(v9)\n           between f47 and f646\n     - r411\n           vertices: p1000(v67) p1111(v55) p681(v11)\n           between f47 and f646\n     - r412\n           vertices: p1000(v67) p1111(v55) p1179(v9)\n           between f646 and f649\n\nWhile executing:  | qhull i Qt\nOptions selected for Qhull 2015.2.r 2016/01/18:\n  run-id 1013305787  incidence  Qtriangulate  _pre-merge  _zero-centrum\n  _max-width  1  Error-roundoff 2e-15  _one-merge 1.8e-14  _near-inside 9.1e-14\n  Visible-distance 1.2e-14  U-coplanar-distance 1.2e-14  Width-outside 2.4e-14\n  _wide-facet 7.3e-14\nLast point added to hull was p1000.  Last merge was #173.\n\nAt error exit:\n\nConvex hull of 1301 points in 4-d:\n\n  Number of vertices: 59\n  Number of coplanar points: 1005\n  Number of facets: 156\n  Number of non-simplicial facets: 5\n\nStatistics for:  | qhull i Qt\n\n  Number of points processed: 67\n  Number of hyperplanes created: 480\n  Number of distance tests for qhull: 53449\n  Number of distance tests for merging: 8257\n  Number of distance tests for checking: 0\n  Number of merged facets: 173\n  Maximum distance of merged point above facet: 2e-14 (1.0x)\n  Maximum distance of merged vertex below facet: -1.5e-14 (0.8x)\n\n\nprecision problems (corrected unless 'Q0' or an error)\n      2 flipped facets\n     61 coplanar horizon facets for new vertices\n    997 coplanar points during partitioning\n      4 degenerate hyperplanes recomputed with gaussian elimination\n      4 nearly singular or axis-parallel hyperplanes\n      1 ridges with multiple neighbors\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mQhullError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-081569b71f0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;31m#    result = min_collusion_solver.result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;31m#    result_up = min_collusion_solver_up.result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0mcomp_histories_upward\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mshare_ties\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmin_collusion_solver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolution\u001b[0m\u001b[0;34m-\u001b[0m \u001b[0mshare_ties\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomp_histories_upward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/missing_bids/analytics.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mseed_delta\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_number_iterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m             \u001b[0minterim_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interim_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m             \u001b[0mlist_solutions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minterim_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolution\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m             selected_guesses = self._get_new_guesses(\n",
      "\u001b[0;32m~/Documents/GitHub/missing_bids/analytics.py\u001b[0m in \u001b[0;36m_interim_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_interim_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         return MinCollusionResult(\n\u001b[0;32m--> 267\u001b[0;31m             self.problem, self.epigraph_extreme_points, self._deviations)\n\u001b[0m\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/missing_bids/analytics.py\u001b[0m in \u001b[0;36mproblem\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mproblem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0mepigraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepigraph_extreme_points\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m         return ConvexProblem(\n\u001b[1;32m    136\u001b[0m             \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetric_extreme_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepigraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/missing_bids/analytics.py\u001b[0m in \u001b[0;36mepigraph_extreme_points\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0menv_perf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_env_with_perf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0minterior_env_perf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_interior_dimensions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_perf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0menv_perf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mConvexHull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minterior_env_perf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvertices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mqhull.pyx\u001b[0m in \u001b[0;36mscipy.spatial.qhull.ConvexHull.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mqhull.pyx\u001b[0m in \u001b[0;36mscipy.spatial.qhull._Qhull.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mQhullError\u001b[0m: QH6271 qhull precision error (qh_check_dupridge): wide merge (13495836560 times wider) due to duplicate ridge with nearly coincident points (1.7e-11) between f649 and f646, merge dist 0.00035, while processing p1000\n- Ignore error with option 'Q12'\n- To be fixed in a later version of Qhull\n- Vertex distance 1.7e-11 is greater than 100 times maximum distance 2.6e-14\n  Please report to bradb@shore.net with steps to reproduce and all output\nERRONEOUS FACET:\n- f649\n    - flags: top new dupridge mergeridge2 flipped\n    - normal:    0.7071  -0.7071 2.079e-07 0.0005327\n    - offset: -0.0005328684\n    - vertices: p1000(v67) p821(v56) p1111(v55) p1179(v9)\n    - neighboring facets: f470 f646 f647 f641\n    - ridges:\n     - r314 tested\n           vertices: p821(v56) p1111(v55) p1179(v9)\n           between f649 and f470\n     - r412\n           vertices: p1000(v67) p1111(v55) p1179(v9)\n           between f646 and f649\n     - r413\n           vertices: p1000(v67) p821(v56) p1179(v9)\n           between f649 and f647\n     - r414\n           vertices: p1000(v67) p821(v56) p1111(v55)\n           between f641 and f649\nERRONEOUS OTHER FACET:\n- f646\n    - flags: top new seen mergehorizon dupridge mergeridge1 flipped\n    - normal:        -0        0       -0       -1\n    - offset:          1\n    - vertices: p1000(v67) p1111(v55) p681(v11) p1179(v9)\n    - neighboring facets: f47 f649\n    - ridges:\n     - r282 tested\n           vertices: p1111(v55) p681(v11) p1179(v9)\n           between f646 and f47\n     - r410\n           vertices: p1000(v67) p681(v11) p1179(v9)\n           between f47 and f646\n     - r411\n           vertices: p1000(v67) p1111(v55) p681(v11)\n           between f47 and f646\n     - r412\n           vertices: p1000(v67) p1111(v55) p1179(v9)\n           between f646 and f649\n\nWhile executing:  | qhull i Qt\nOptions selected for Qhull 2015.2.r 2016/01/18:\n  run-id 1013305787  incidence  Qtriangulate  _pre-merge  _zero-centrum\n  _max-width  1  Error-roundoff 2e-15  _one-merge 1.8e-14  _near-inside 9.1e-14\n  Visible-distance 1.2e-14  U-coplanar-distance 1.2e-14  Width-outside 2.4e-14\n  _wide-facet 7.3e-14\nLast point added to hull was p1000.  Last merge was #173.\n\nAt error exit:\n\nConvex hull of 1301 points in 4-d:\n\n  Number of vertices: 59\n  Number of coplanar points: 1005\n  Number of facets: 156\n  Number of non-simplicial facets: 5\n\nStatistics for:  | qhull i Qt\n\n  Number of points processed: 67\n  Number of hyperplanes created: 480\n  Number of distance tests for qhull: 53449\n  Number of distance tests for merging: 8257\n  Number of distance tests for checking: 0\n  Number of merged facets: 173\n  Maximum distance of merged point above facet: 2e-14 (1.0x)\n  Maximum distance of merged vertex below facet: -1.5e-14 (0.8x)\n\n\nprecision problems (corrected unless 'Q0' or an error)\n      2 flipped facets\n     61 coplanar horizon facets for new vertices\n    997 coplanar points during partitioning\n      4 degenerate hyperplanes recomputed with gaussian elimination\n      4 nearly singular or axis-parallel hyperplanes\n      1 ridges with multiple neighbors\n"
     ]
    }
   ],
   "source": [
    "k_array = [0.01, 0.5, 1, 1.5]\n",
    "comp_histories = []\n",
    "\n",
    "deviations = [-.015, .0, .001]\n",
    "filter_ties = auction_data.FilterTies(tolerance=.0001)\n",
    "filtered_data = filter_ties(tsuchiura_before_min_price)\n",
    "demands = [filtered_data.get_counterfactual_demand(rho) for rho in deviations]\n",
    "\n",
    "share_ties = filter_ties.get_ties(tsuchiura_before_min_price).mean()\n",
    "\n",
    "\n",
    "for k_0 in k_array:\n",
    "    constraints = [environments.MarkupConstraint(max_markup=.5, min_markup=.02), \n",
    "               environments.InformationConstraint(k=k_0, sample_demands=demands)]\n",
    "    \n",
    "    min_collusion_solver = analytics.MinCollusionIterativeSolver(\n",
    "        data=filtered_data, \n",
    "        deviations=deviations, \n",
    "        metric=analytics.IsNonCompetitive, \n",
    "        plausibility_constraints=constraints, \n",
    "        num_points=1000.0, \n",
    "        seed=0, \n",
    "        project=True, \n",
    "        filter_ties=None,\n",
    "        number_iterations=150,\n",
    "        confidence_level=.95,\n",
    "        moment_matrix=auction_data.moment_matrix(deviations, 'slope'),\n",
    "        moment_weights=np.array([0, 0.1, 1])\n",
    "    )\n",
    "\n",
    "        \n",
    "    comp_histories.append(1 - (1-share_ties)*min_collusion_solver.result.solution - share_ties)\n",
    "\n",
    "print(comp_histories)\n",
    "#print(comp_histories_upward)\n",
    "\n",
    "comp_histories_upward = []\n",
    "\n",
    "\n",
    "deviations = [.0, .001]\n",
    "demands = [filtered_data.get_counterfactual_demand(rho) for rho in deviations]\n",
    "\n",
    "for k_0 in k_array:\n",
    "    constraints = [environments.MarkupConstraint(max_markup=.5, min_markup=.02), \n",
    "               environments.InformationConstraint(k=k_0, sample_demands=demands)]\n",
    "    \n",
    "    \n",
    "    min_collusion_solver = analytics.MinCollusionIterativeSolver(\n",
    "        data=filtered_data, \n",
    "        deviations=deviations, \n",
    "        metric=analytics.IsNonCompetitive, \n",
    "        plausibility_constraints=constraints, \n",
    "        num_points=1000.0, \n",
    "        seed=0, \n",
    "        project=True, \n",
    "        filter_ties=None,\n",
    "        number_iterations=150,\n",
    "        confidence_level=.95,\n",
    "        moment_matrix=auction_data.moment_matrix(deviations, 'slope'),\n",
    "        moment_weights=np.array([0, 1])\n",
    "    )\n",
    "\n",
    "        \n",
    "#    result = min_collusion_solver.result\n",
    "#    result_up = min_collusion_solver_up.result\n",
    "    comp_histories_upward.append(1 - (1-share_ties)*min_collusion_solver.result.solution- share_ties)\n",
    "\n",
    "print(comp_histories_upward)\n",
    "\n",
    "plt.plot(k_array,comp_histories_upward, 'k.:', label=\"comp. histories; upward deviation\")\n",
    "plt.plot(k_array,comp_histories, 'k.-', label=\"comp. histories; upward + downwarad deviations\")\n",
    "#    plt.plot(k_array,comp_upward_ex_ties, 'k.--', label=\"upward deviation and ties\")\n",
    "#    plt.plot(k_array,comp_ex_ties, 'k.-', label=\"competitive histories\")\n",
    "plt.legend(loc='lower right')\n",
    "plt.axis([0, 1.01, 0, 1.01])\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('share of competitive histories')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bids = tsuchiura_data.df_bids.loc[tsuchiura_before_min_price.data.norm_bid > 0.95]\n",
    "tsuchiura_above_95 = auction_data.AuctionData.from_clean_bids(df_bids)\n",
    "tsuchiura_above_95.df_bids.equals(df_bids)\n",
    "\n",
    "df_bids = tsuchiura_data.df_bids.loc[tsuchiura_before_min_price.data.norm_bid <= 0.95]\n",
    "tsuchiura_below_95 = auction_data.AuctionData.from_clean_bids(df_bids)\n",
    "tsuchiura_below_95.df_bids.equals(df_bids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_array = [0.01, 0.5, 1]\n",
    "comp_histories_above = []\n",
    "\n",
    "deviations = [-.015, .0, .0008]\n",
    "filter_ties = auction_data.FilterTies(tolerance=.0001)\n",
    "filtered_data = filter_ties(tsuchiura_above_95)\n",
    "demands = [filtered_data.get_counterfactual_demand(rho) for rho in deviations]\n",
    "\n",
    "share_ties = filter_ties.get_ties(tsuchiura_above_95).mean()\n",
    "\n",
    "\n",
    "for k_0 in k_array:\n",
    "    constraints = [environments.MarkupConstraint(max_markup=.5, min_markup=.02), \n",
    "               environments.InformationConstraint(k=k_0, sample_demands=demands)]\n",
    "    \n",
    "    min_collusion_solver = analytics.MinCollusionIterativeSolver(\n",
    "        data=filtered_data, \n",
    "        deviations=deviations, \n",
    "        metric=analytics.IsNonCompetitive, \n",
    "        plausibility_constraints=constraints, \n",
    "        num_points=1000.0, \n",
    "        seed=0, \n",
    "        project=True, \n",
    "        filter_ties=None,\n",
    "        number_iterations=150,\n",
    "        confidence_level=.95,\n",
    "        moment_matrix=auction_data.moment_matrix(deviations, 'slope'),\n",
    "        moment_weights=np.array([0, 0.1, 1])\n",
    "    )\n",
    "\n",
    "        \n",
    "    comp_histories_above.append(1 - (1-share_ties)*min_collusion_solver.result.solution - share_ties)\n",
    "\n",
    "print(comp_histories_above)\n",
    "#print(comp_histories_upward)\n",
    "\n",
    "comp_histories_below = []\n",
    "\n",
    "filtered_data = filter_ties(tsuchiura_below_95)\n",
    "demands = [filtered_data.get_counterfactual_demand(rho) for rho in deviations]\n",
    "\n",
    "\n",
    "\n",
    "for k_0 in k_array:\n",
    "    constraints = [environments.MarkupConstraint(max_markup=.5, min_markup=.02), \n",
    "               environments.InformationConstraint(k=k_0, sample_demands=demands)]\n",
    "    \n",
    "    \n",
    "    min_collusion_solver = analytics.MinCollusionIterativeSolver(\n",
    "        data=filtered_data, \n",
    "        deviations=deviations, \n",
    "        metric=analytics.IsNonCompetitive, \n",
    "        plausibility_constraints=constraints, \n",
    "        num_points=1000.0, \n",
    "        seed=0, \n",
    "        project=True, \n",
    "        filter_ties=None,\n",
    "        number_iterations=150,\n",
    "        confidence_level=.95,\n",
    "        moment_matrix=auction_data.moment_matrix(deviations, 'slope'),\n",
    "        moment_weights=np.array([0, 0.1, 1])\n",
    "    )\n",
    "\n",
    "        \n",
    "#    result = min_collusion_solver.result\n",
    "#    result_up = min_collusion_solver_up.result\n",
    "    comp_histories_below.append(1 - (1-share_ties)*min_collusion_solver.result.solution- share_ties)\n",
    "\n",
    "print(comp_histories_below)\n",
    "\n",
    "plt.plot(k_array,comp_histories_below, 'k.:', label=\"comp. histories; below .95\")\n",
    "plt.plot(k_array,comp_histories_above, 'k.-', label=\"comp. histories; above .95\")\n",
    "#    plt.plot(k_array,comp_upward_ex_ties, 'k.--', label=\"upward deviation and ties\")\n",
    "#    plt.plot(k_array,comp_ex_ties, 'k.-', label=\"competitive histories\")\n",
    "plt.legend(loc='lower right')\n",
    "plt.axis([0, 1.5, 0, 1.01])\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('share of competitive histories')    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
